[["index.html", "AnVIL Demos About this Series AnVIL Collection", " AnVIL Demos January 23, 2025 About this Series Welcome to our series of demos introducing the Genomic Data Science Analysis, Visualization, and Informatics Lab-space (AnVIL) of the National Human Genome Research Institute (NHGRI). The AnVIL is a cloud-based platform designed to provide researchers with secure and controlled access to genomic data, as well as tools for analysis and visualization. With the increasing availability of genomic data, there is a growing need for efficient and effective tools for data analysis and interpretation. The AnVIL platform addresses this need by providing researchers with easy access to a growing collection of genomic data, as well as powerful tools for analysis and visualization. Our series of demos will guide you through the various features of the AnVIL platform, and show you how it can help you to accelerate your research and make new discoveries in the field of genomics. Whether you are new to the field of genomics or an experienced researcher, these demos will provide you with valuable insights into the AnVIL platform and its capabilities. We look forward to helping you unlock the full potential of genomic data science through the AnVIL platform. Learn more about AnVIL by visiting https://anvilproject.org or reading the article in Cell Genomics. AnVIL Collection Please check out our full collection of AnVIL and related resources: https://hutchdatascience.org/AnVIL_Collection/ "],["what-is-anvil-overview.html", "1 Overview 1.1 Background 1.2 About this Demo 1.3 Skills Level 1.4 Learning Objectives", " 1 Overview 1.1 Background Over the past 20 years, there has been tremendous growth in human genomics, with millions of human genomes sequenced and many more to come in the future. This data, along with other biomedical information, has the potential to greatly improve our understanding of healthy living and transform healthcare. To achieve these goals, we need new approaches to research that involve cloud computing, which is the only way to effectively share and analyze data at this scale. The traditional method of genomic data sharing through centralized data warehouses is becoming unsustainable and inefficient. It creates redundant infrastructure and administrative inefficiencies that make collaborative analysis challenging, especially as datasets increase in size. This approach also leads to high transfer and download costs and poses security and compliance risks. The NHGRI Genomic Data Science Analysis, Visualization, and Informatics Lab-Space, or AnVIL, inverts the traditional model, providing a cloud environment for the analysis of large genomic and related datasets. By providing a secure, unified environment for data management and compute, AnVIL eliminates the need for data movement, allows for active threat detection and monitoring, and provides elastic, shared computing resources that can be acquired as needed. AnVIL currently provides secure access to hundreds of thousands of NHGRI datasets spanning nearly 5 petabytes of data and is built from a set of established components that are accessed and connected through the AnVIL Portal at https://anvilproject.org/ . The AnVIL homepage provides researchers an entry point into these tools, along with documentation, data browser, and links to related resources. 1.2 About this Demo The Welcome to AnVIL demo provides an overview of the AnVIL platform, its purpose, and how it can benefit researchers and the broader genomics community. We highlight some of the historic challenges of analyzing and sharing large-scale genomic data and describe how AnVIL provides a cloud-based solution for accessing and analyzing such data. We also cover key features and functionalities of AnVIL, including its compatibility with popular analysis tools/ Finally, we emphasize the importance of collaboration and community engagement in driving AnVIL’s development and future growth, providing resources to customize your journey with AnVIL. 1.3 Skills Level Genetics Novice: no genetics knowledge needed Programming skills Novice: no programming experience needed 1.4 Learning Objectives Understand the benefits of using cloud computing for genomic data analysis and the limitations of traditional data-sharing paradigms. Identify the main features and tools available on the AnVIL platform and their potential applications in genomics research. Learn how to navigate and access a Workspace, the starting point for a basic analysis using the AnVIL tools. Identify potential use cases for the AnVIL platform in your own research projects. Learn about additional resources to self-guide your discovery on AnVIL. "],["what-is-anvil-preparation.html", "2 Preparation 2.1 Review Key Concepts", " 2 Preparation 2.1 Review Key Concepts Learn about why AnVIL has been created, what features AnVIL offers, how AnVIL is being used, and how to get started in this ~20 min video (slides) "],["what-is-anvil-exercises.html", "3 Exercises 3.1 Launch Terra 3.2 Clone HPRC Workspace 3.3 Start a Cloud Environment 3.4 Find Tidbits 3.5 Enter Terminal 3.6 Shut Down", " 3 Exercises 3.1 Launch Terra Open anvilproject.org and click on “Launch” Terra 3.2 Clone HPRC Workspace At anvil.terra.bio/#workspaces Enter hprc in the search box Click on the “Public” tab Click on AnVIL_HPRC Click on the circle with three vertical dots in the upper right corner and select “Clone” 3.3 Start a Cloud Environment Click on the Environment Configuration (cloud icon) Select Jupyter Settings Scroll down and click “Create” 3.4 Find Tidbits In the Dashboard tab, what are three types of sequencing data that are available? In the Data tab participant table, what two superpopulations have the most participants? In the Data tab sample table, how many samples lack any ilmn data? In the Data tab assembly_sample table, what is the command to download the HG002 mat_fasta file? 3.5 Enter Terminal In the Analysis tab, click on Terminal Make a working copy of the HG002 mat_fasta NOTE: Requester pays buckets require -u &lt;google-project-id&gt; [ref] Examine file with ls -l and zcat *.fa.gz | head gsutil cp &#39;gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/working/HPRC_PLUS/HG002/assemblies/year1_f1_assembly_v2_genbank/HG002.maternal.f1_assembly_v2_genbank.fa.gz&#39; . 3.6 Shut Down Click on the Environment Configuration (cloud icon) Select Jupyter Settings Scroll down and click “Delete Environment” Select “Delete” after deciding to keep or delete your persistent disk Click “hamburger” icon in the upper left, expand your name, select Cloud Environments and confirm no unnecessary resources are running "],["what-is-anvil-instructor-guide.html", "4 Instructor Guide 4.1 Timeline", " 4 Instructor Guide 4.1 Timeline Here is one possible way to budget time for a synchronous event: Activity Duration Review Key Concepts 15 min Q &amp; A 5 min Exercises 15 min Q &amp; A 5 min Here is one way to balance exercises between hands-on (HO) and follow-along (FA): Activity Style Launch Terra HO Clone HPRC Workspace HO Start a Cloud Environment FA Find Tidbits HO Enter Terminal FA Shut Down FA "],["scale-with-workflows-overview.html", "5 Overview 5.1 Skills Level 5.2 Learning Objectives", " 5 Overview One of the great features of AnVIL is that it “brings the analysis to the data”. Rather than downloading and storing your own copy of an AnVIL dataset, you can simply create links to the existing data, and run analyses using those links. You can find a slide overview of this demo here. You can also check out the video version here. 5.1 Skills Level Genetics Novice: no genetics knowledge needed Programming skills Novice: no programming experience needed 5.2 Learning Objectives Identify interesting datasets in the AnVIL Dataset Catalog Navigate an AnVIL Workspace Combine data from multiple existing datasets into your own Workspace Find Workflows in Dockstore Run a Workflow on AnVIL with your combined data "],["scale-with-workflows-preparation.html", "6 Preparation 6.1 Review Key Concepts 6.2 Create AnVIL account 6.3 Clone Workspace 6.4 Start Cloud Environment", " 6 Preparation If you plan to follow along with these exercises, there are a couple of things you will need to take care of first: Quickstart For this Demo, you will need to: Clone your own copy of the demos-combine-data-workspaces Workspace. Launch a Jupyter Cloud Environment with the default settings (in your cloned Workspace). Review a few key AnVIL concepts to set context for the Demo. (If you are participating in a live workshop, these will be covered by the instructor. Otherwise, watch the video below.) If you feel comfortable, you can take care of these things yourself and then proceed to the Exercises. Otherwise, the instructions below will walk you through the process. 6.1 Review Key Concepts This 5-min video provides a high level summary of the exercises to follow. Several important concepts are introduced to provide context for the exercises including 1) the AnVIL data flow that minimizes costs and redundancy and 2) increasing number of production quality workflows in Dockstore (slides). 6.2 Create AnVIL account You will need an AnVIL account in order to view Workspaces and run analyses. If you do not already have an account, follow these instructions to set one up. (You do not need to link any external accounts for these exercises.) Make sure that your Instructor (if participating in a workshop) or PI / Lab Manager has your username, so that they can add you to an appropriate Billing Project. You can’t clone or create Workspaces on AnVIL without a Billing Project. 6.3 Clone Workspace When you “clone” a copy of an AnVIL Workspace, it can take a few minutes for everything to propagate to your new Workspace. If you are participating in a course or workshop, your instructor may have you start by cloning the Workspace, so that it is ready by the time you need it. (If you are working at your own pace, feel free to come back to this step later, when you’re ready to start using the Workspace.) Follow the instructions below to clone your own copy of the Workspace for this Demo. This will not work until your instructor has given you permission to spend money to “rent” the computers that will power your analyses (by adding you to a “Billing Project”). On AnVIL, you access files and computers through Workspaces. Each Workspace functions almost like a mini code laboratory - it is a place where data can be examined, stored, and analyzed. The first thing we want to do is to copy or “clone” a Workspace to create a space for you to experiment. This will give you access to the files you will need (data, code) the computing environment you will use Tip At this point, it might make things easier to open up a new window in your browser and split your screen. That way, you can follow along with this guide on one side and execute the steps on the other. To clone an AnVIL Workspace: Open Terra - use a web browser to go to anvil.terra.bio In the drop-down menu on the left, navigate to “Workspaces”. Click the triple bar in the top left corner to access the menu. Click “Workspaces”. You are automatically directed to the “MY WORKSPACES” tab. Here you can see any Workspaces that have been shared with you, along with your permission level. Depending on how your instructor has set things up, you may or may not see any Workspaces in this tab. Locate the Workspace demos-combine-data-workspaces. (The images below show the SARS-CoV-2-Genome Workspace as an example, but you should look for the Workspace demos-combine-data-workspaces.) If it has been shared with you ahead of time, it will appear in “MY WORKSPACES”. Otherwise, select the “PUBLIC” tab. In the top search bar, type the Workspace name demos-combine-data-workspaces. You can also go directly to the Workspace by clicking this link: https://anvil.terra.bio/#workspaces/anvil-outreach/demos-combine-data-workspaces. Clone the workspace by clicking the teardrop button (). Select “Clone”. Or, if you have opened the Workspace, you can find the teardrop button on the top right of the Workspace. You will see a popup box appear, asking you to configure your Workspace Give your Workspace clone a name by adding an underscore (“_“) and your name. For example, \"demos-combine-data-workspaces_Firstname_Lastname\". Select the Billing Project provided by your instructor. Leave the bottom two boxes as-is. Click “CLONE WORKSPACE”. The new Workspace should now show up under “MY WORKSPACES”. You now have your own copy of the Workspace to work in. Now your Workspace should be ready for you by the time you need it. 6.4 Start Cloud Environment Pause here if you are not going to be doing the Exercises right away. Once you start up Jupyter, it will cost money to keep it running. It costs a few cents an hour, so it’s quite cheap as long as you use it responsibly. But it can add up if you leave it running for days or weeks when you don’t need it. If you are ready to proceed through the Exercises, go ahead and follow the instructions below to start Jupyter. It will take a few minutes to start up. You can work through the first couple of Exercises while you wait. AnVIL is very versatile and can scale up to use very powerful cloud computers. It’s very important that you select the cloud computing environment described here to avoid runaway costs. Open Terra - use a web browser to go to anvil.terra.bio In the drop-down menu on the left, navigate to “Workspaces”. Click the triple bar in the top left corner to access the menu. Click “Workspaces”. Click on the name of your Workspace. You should be routed to a link that looks like: https://anvil.terra.bio/#workspaces/&lt;billing-project&gt;/&lt;workspace-name&gt;. Click on the cloud icon on the far right to access your Cloud Environment options. If you don’t see this icon, you may need to scroll to the right. In the dialogue box, click the “Settings” button under Jupyter. You will see some configuration options for the Jupyter cloud environment, and a list of costs because it costs a small amount of money to use cloud computing. Leave everything else as-is. To create your Jupyter Cloud Environment, scroll down and click the “CREATE” button. The dialogue box will close and you will be returned to your Workspace. You can see the status of your cloud environment by hovering over the Jupyter icon. It will take a few minutes for Terra to request computers and install software. When your environment is ready, its status will change to “Running”. Click on the “ANALYSES” tab to create or open a Jupyter Notebook. From the ANALYSES tab, you can click on the name of an existing Jupyter Notebook to view and launch it, or click the “START” button to create a new Notebook. Once you have clicked “CREATE” and your cloud environment status is “Creating”, you can go ahead and start the Exercises. Your cloud environment should be ready by the time you need it. "],["scale-with-workflows-exercises.html", "7 Exercises 7.1 Explore Dataset Catalog 7.2 Explore HPRC Workspace 7.3 Combine Data Workspace 7.4 Explore Dockstore Workflows 7.5 Run qc-analysis-pipeline", " 7 Exercises The following exercises will walk you through the process of finding datasets that are stored in AnVIL Workspaces and bringing that data into your own Workspace so that you can analyze it. To follow along with these exercises, you will need to complete the steps described in the Preparation guide for this demo. 7.1 Explore Dataset Catalog First we will take a look at the AnVIL Dataset Catalog. Here you can browse the datasets available on AnVIL. Exercise Use a web browser to navigate to anvilproject.org/data/ and answer the following questions. Q1. Which Consortium has the most participants? You can click on a column name to sort by that column. Click again to switch between ascending and descending. Q2. Where would you find data from the Genotype-Tissue Expression (GTEx) Project? You can use the filters on the left to find specific datasets. Click on either the Consortium or the Study filter to search for GTEx data. Q3. How many Workspaces have consent code NRES (No REStrictions on data use)? You can use the filters on the left to browse and narrow down on datasets that fit your needs. Click on the Consent Code filter to select for datasets that you can access. Learn more about consent codes here. Now you know how to find AnVIL datasets! To access the data in these datasets, you will need to access the Terra Workspace where the data is stored. You can find links to the Terra Workspaces in the Workspaces tab. Note that, if a Workspace contains protected data, you will need to obtain the appropriate permissions before you can open the Workspace. For these GTEx datasets, AnVIL_GTEx_public_data (with consent code NRES) is available to anyone on AnVIL, but other GTEx Workspaces require permission to access. 7.2 Explore HPRC Workspace Next we will explore one of the Workspaces from the AnVIL Dataset Catalog, so you can see where the data lives. For this exercise, we will look at data from the Human Pangenome Reference Consortium. You can find the Workspace that contains the data by searching for the “HPRC” Consortium in the AnVIL Dataset Catalog and clicking on the Terra Workspace link, or you can navigate there directly through this link: https://anvil.terra.bio/#workspaces/anvil-datastorage/AnVIL_HPRC. 7.2.1 What is a Workspace? Workspaces are the building blocks of projects in Terra. Inside a Workspace, you can run analyses, launch interactive tools like RStudio and Galaxy, store data, and share results. The AnVIL_HPRC Workspace is being used to store and share data from the Human Pangenome Reference Consortium. Note that, since you are only a “Reader”, you will be unable to do any computations directly in this Workspace. To run analyses, you will need a Workspace of your own. Workspaces can serve different purposes. For example, it’s often useful to use one Workspace just for organizing primary data, and then to carry out analyses in a separate Workspace. Storing data in a standalone Workspace helps keep it clean and organized, since it won’t get cluttered up with results and intermediate files from your analyses. It also ensures you can easily see and manage who has access to the data, and allows multiple AnVIL users to use the data without getting in each others’ way. 7.2.2 Dashboard When you first open a Workspace, you will be directed to the Dashboard tab. The Dashboard is like a README for the Workspace - it should contain information to help you understand the purpose and organization of the Workspace. On the right, you can see some basic information about the Workspace such as the usernames of the Owners as well as your permission level for the Workspace. The left side typically contains a description of the Workspace’s contents and purpose. Exercise Q1. What three strategies were used to build pangenomes? Look through the Workspace’s description to see what information has been provided about the data in this Workspace. 7.2.3 Data The Data tab contains all the files associated with the Workspace - data, metadata, workflow outputs, etc. Terra provides Data Tables to help organize data and results. Exercise Take a minute to look through the Data Tables for the AnVIL_HPRC Workspace. Q2. What demographic information is available in the Data Table named participant? Q3. What types of files are linked to in the Data Table named assembly_sample? If you’re not sure what these files are from looking at the column and file names, check the Workspace Dashboard for more information about the assemblies. A key feature of Terra is that Data Tables can link to files in other Workspaces or even files that live outside of Terra. This means that you don’t need to maintain your own copy of AnVIL datasets; you can simply link to the data from a Data Table within your own Workspace to use it in your workflows. 7.3 Combine Data Workspace Next we will go over how to set up a Data Table so that you can use data from another Workspace in your own analysis. For this exercise, you will need your own copy of the demos-combine-data-workspaces Workspace. If you have not already done so, follow the instructions in the Preparation section to clone a copy of the Workspace now. 7.3.1 Open your Workspace To get started, navigate to your cloned copy of demos-combine-data-workspaces. You can find your Workspace in Terra by clicking on “Workspaces” in the dropdown menu, or you can go there directly at anvil.terra.bio/#workspaces. Once there, you should see your Workspace under the “MY WORKSPACES” tab. It may also show up in your recently viewed Workspaces. Click on the Workspace name to open it. Make sure you are in your copy of the Workspace. If you are in the original Workspace, you will not have permission to start up Jupyter and run commands. 7.3.2 Open Jupyter Notebook There are multiple ways to manage Data Tables on AnVIL; for this exercise we will use the Anvil R package, which we will run using a Jupyter cloud environment. The AnVIL package provides a wide range of functions for programmatically interacting with AnVIL. To help you get started, we have provided a copy of a Jupyter Notebook that uses the AnVIL package to create Data Tables linking out to data in another Workspace. For this exercise, you will make a couple of adjustments to the Notebook, so that it links properly to your Workspace (instead of the original Workspace). Within your Workspace, the ANALYSIS tab holds your Notebooks (Jupyter and R Markdown). By clicking on a Notebook, you can preview a static copy of the Notebook. Clicking the “OPEN” button launches the Notebook in a cloud environment so that you can edit and run code. (The “PLAYGROUND” option also lets you edit and run code, but your changes will not be saved.) Exercise In your Workspace, navigate to the “ANALYSIS” tab. Click on combine-data-workspaces.ipynb to view the Notebook for this exercise, and click the “Open” button so you can edit and run it. The Notebook will launch quickly if you already have a Jupyter Cloud Environment set up. If Jupyter is not already set up, the configuration menu will appear. The default settings are fine for this exercise, so scroll to the bottom and click “Create”. It will take a few minutes for Jupyter to start up. This Notebook has four code cells that you will run, after making some edits. 7.3.3 Load Packages The first code cell loads R packages that are needed for this exercise. You do not need to make any adjustments here. Exercise 1. Click on the first code cell, then click the Run button to load the packages. 7.3.4 Retrieve original file locations The next two cells find the links to the original data. Here we are bringing in data from two different Workspaces, AnVIL_HPRC and 1000G-high-coverage-2019, which contains data from the Human Pangenome Reference Consortium and the 1000 Genomes Project, respectively. avworkspace( \"anvil-datastorage/AnVIL_HPRC\" ) tells the AnVIL package what Workspace to access df_sample_HPRC &lt;- avtable( \"sample\" ) %&gt;% tells it to look at the table named “sample”. The subsequent commands select which columns and rows to import into our Workspace. These commands differ between the two code blocks because the Tables in the two source Workspaces have different structures. slice_head( n=2 ) gets only the first two samples. It’s often a good idea to start off a new analysis by working with just a few samples. This can help you minimize wasted time and computing expenses while you figure out your pipeline, and can also help you estimate what your costs will be for processing larger dataset before committing to a large Workflow run. To keep this exercise short and cheap, we’re just importing a few samples into your Workspace, but when working on your own projects you can use the same process to import whole tables. It does not cost anything to add these samples to your Data Table, since you are not storing them in your own Workspace, only linking to them in another Workspace. Costs come into it when you start running analyses on the samples (as we will in a later exercise), so take care not to unintentionally run an expensive analysis on a large table of samples. Exercise 2. Modify the code in both cells to get 3 samples instead of 2, and run each cell. You should see a table listing out the samples appear below each cell. Confirm that there are 3 samples in each table. This step chose the samples we want from the original Workspace, but has not yet created a Data Table that links to them in your own Workspace. 7.3.5 Exported combined Data Table The next code block accomplishes a few things: The bind_rows() command combines data from the two different Workspaces into a single data table, so that you can conveniently work with all the data at once in your Workflows. It also adds a column to keep track of which samples came from which original Workspace. avtable_import( entity=\"sample_id\", namespace=\"anvil-outreach\", name=\"demos-combine-data-workspaces\" ) creates a Data Table in your Workspace that links to the original data, so that you can easily use it in your analyses. This is the line that we need to modify so that the Data Table is created in your Workspace. Exercise You will need two pieces of information so that the AnVIL package can locate your Workspace to create the new Data Table: The namespace (the Workspace’s Billing Project) The Workspace name You can find both of these at the end of the URL for your Workspace which is structured like this: anvil.terra.bio/#workspaces/namespace/name For example, for this Workspace: https://anvil.terra.bio/#workspaces/anvil-outreach/demos-combine-data-workspaces_KCox_20230616 The namespace is anvil-outreach The name is demos-combine-data-workspaces_KCox_20230616 3. Modify the code in your Notebook so that it points to your Workspace, and run the cell. If this command is successful, you will not see your new table in your Notebook, but if you look in the Data tab of your Workspace you should now see the sample Data Table has 6 rows in it. 7.3.6 Session Info It’s generally a good idea to document information about the packages (and their versions) you used while running the analysis. The last codeblock uses the sessionInfo() command to do just that. 7.3.7 View your new Data Table As a last step, take a look at the Data Tab in your Workspace. You should now see a table named sample that contains 6 rows - 3 with project “HPRC” and 3 with project “1000G”. Note that for this exercise we preloaded the Workspace with 4 samples - if you only see 4 rows then double check your Notebook: Did you remember to “Run” each code cell after you edited it? Did you change the number of samples to link from 2 to 3 for each table? Did you update the avtable_import command to point to your Workspace? If you run into any trouble, don’t worry! You can carry out the remaining exercises using the 4 samples we provided for you, and you can visit our community support forum at help.anvilproject.org with any questions. 7.4 Explore Dockstore Workflows Once you have set up Data Tables in your Workspace, you can analyze the data using Workflows. To introduce you to Workflows, we will first take a look at the AnVIL Workflows available through Dockstore. The Dockstore platform is a repository for scalable bioinformatics tools and workflows. You can find Workflows for AnVIL by clicking on the “Organizations” tab and searching for AnVIL. Here you can find many Workflows which you can import into your AnVIL Workspace to use in your own analyses. These Workflows are organized into collections to make them easier to find. Exercise Go to dockstore.org, find the AnVIL Organization, and take a look at the Workflows that are available. Q1. How many GATK4 workflows focus on CNVs? Now let’s take a look at the qc-analysis-pipeline, which we will be running on our data. Under the AnVIL Organization is a collection called “Quality Control Workflows”. Here you can find the qc-analysis-pipeline. Clicking on the name of the Workflow will bring you to a page with detailed information about the Workflow, including the .wdl files for the Workflow. From here, you can import the Workflow into your Workspace using the Launch button. Don’t do this right now, or, if you do, import it with a different name (not qc-analysis-pipeline) so you don’t overwrite the Workflow that already exists in your Workspace. There are some additional configuration steps that are needed to make sure the Workflow is set up properly to run on the desired files in your Workspace. For the sake of time, we have provided a preconfigured version of this Workflow in the Workspace you cloned. You can learn more about configuring Workflows in the Terra Documentation on Workflows. 7.5 Run qc-analysis-pipeline For our final exercise, we will run the qc-analysis-pipeline on the data we retrieved. Note that Workflow runs can take a few hours to go through, so this exercise will walk you through submitting it, but you will need to check back later for the results. You should receive an email when it’s done (at the email address you use for AnVIL). AnVIL Workspaces have two tabs dedicated to Workflows The “WORKFLOWS” tab is where you configure and submit Workflow runs for processing. The “JOB HISTORY” tab is where you monitor the progress of submitted Workflows. Under the “WORKFLOWS” tab you will see any Workflows that have been imported into your Workspace. If you import a Workflow from Dockstore (using the Launch with AnVIL button) or from another Workspace, you will see it here. For this exercise, the qc-analysis-pipeline has already been imported for you. Exercise Go to your Workspace on AnVIL and open the “WORKFLOWS” tab. 1. Click on the qc-analysis-pipeline card to configure the Workflow. 2. Confirm settings “Run workflow(s) with inputs defined by data table” is selected The root entity type should be “sample”. This means it will look at the “sample” Data Table to find inputs. 3. Choose samples - click the “SELECT DATA” button and check the samples you want to run the Workflow on. You should see 6 samples. 4. Click the “RUN ANALYSIS” button. You can view the status of your Workflow run by navigating to the “JOB HISTORY” tab. You can see more details by clicking on the name of the Workflow in the “Submission” column. Once your Workflow run is complete, you will be able to view the results in your Workspace’s “DATA” tab. "],["scale-with-workflows-instructor-guide.html", "8 Instructor Guide 8.1 Timeline 8.2 Example", " 8 Instructor Guide 8.1 Timeline Here is one possible way to budget time for a synchronous event: Activity Duration 1-slide Overview, Clone, Launch 5 min Key Concepts 5 min Exercises 15 min Q &amp; A 5 min Here is one way to balance exercises between hands-on (HO) and follow-along (FA): Activity Style Explore Dataset Catalog FA Explore Workspace FA Combine Data Workspace HO Explore Dockstore Workflows FA Run qc-analysis-pipeline HO 8.2 Example Here is a recording of this material at our monthly AnVIL Demos series "],["single-cell-with-bioconductor-overview.html", "9 Overview 9.1 Skills Level 9.2 Learning Objectives", " 9 Overview The iSEE Bioconductor package is a powerful tool for visualizing and exploring single-cell RNA-seq data. The iSEE viewer provides an interactive interface for exploring gene expression patterns, performing dimensionality reduction, clustering cells, visualizing metadata, and conducting differential expression analysis. In this demo, we’ll learn how to launch the iSEE viewer in AnVIL’s RStudio environment. 9.1 Skills Level Genetics Beginner: some genetics knowledge helpful Programming skills Beginner: some programming experience helpful 9.2 Learning Objectives Launch Terra Clone Workspace Launch RStudio-Bioconductor maintained cloud environment Launch iSEE viewer Create plots for investigating expression of different cell types Shut down RStudio "],["single-cell-with-bioconductor-preparation.html", "10 Preparation 10.1 Review Background 10.2 Create AnVIL account 10.3 Clone Workspace 10.4 Start Cloud Environment", " 10 Preparation If you plan to follow along with these exercises, there are a couple of things you will need to take care of first: 10.1 Review Background If you aren’t already familiar with RStudio, Bioconductor, and single cell RNA sequencing data analysis, we encourage you to check out our background slides here. 10.2 Create AnVIL account You will need an AnVIL account in order to view Workspaces and run analyses. If you do not already have an account, follow these instructions to set one up. (You do not need to link any external accounts for these exercises.) Make sure that your Instructor (if participating in a workshop) or PI / Lab Manager has your username, so that they can add you to an appropriate Billing Project. You can’t clone or create Workspaces on AnVIL without a Billing Project. 10.3 Clone Workspace When you “clone” a copy of an AnVIL Workspace, it can take a few minutes for everything to propagate to your new Workspace. If you are participating in a course or workshop, your instructor may have you start by cloning the Workspace, so that it is ready by the time you need it. (If you are working at your own pace, feel free to come back to this step later, when you’re ready to start using the Workspace.) Follow the instructions below to clone your own copy of the Workspace for this Demo. This will not work until your instructor has given you permission to spend money to “rent” the computers that will power your analyses (by adding you to a “Billing Project”). On AnVIL, you access files and computers through Workspaces. Each Workspace functions almost like a mini code laboratory - it is a place where data can be examined, stored, and analyzed. The first thing we want to do is to copy or “clone” a Workspace to create a space for you to experiment. This will give you access to the files you will need (data, code) the computing environment you will use Tip At this point, it might make things easier to open up a new window in your browser and split your screen. That way, you can follow along with this guide on one side and execute the steps on the other. To clone an AnVIL Workspace: Open Terra - use a web browser to go to anvil.terra.bio In the drop-down menu on the left, navigate to “Workspaces”. Click the triple bar in the top left corner to access the menu. Click “Workspaces”. You are automatically directed to the “MY WORKSPACES” tab. Here you can see any Workspaces that have been shared with you, along with your permission level. Depending on how your instructor has set things up, you may or may not see any Workspaces in this tab. Locate the Workspace demos-combine-data-workspaces. (The images below show the SARS-CoV-2-Genome Workspace as an example, but you should look for the Workspace demos-combine-data-workspaces.) If it has been shared with you ahead of time, it will appear in “MY WORKSPACES”. Otherwise, select the “PUBLIC” tab. In the top search bar, type the Workspace name demos-combine-data-workspaces. You can also go directly to the Workspace by clicking this link: https://anvil.terra.bio/#workspaces/anvil-outreach/demos-combine-data-workspaces. Clone the workspace by clicking the teardrop button (). Select “Clone”. Or, if you have opened the Workspace, you can find the teardrop button on the top right of the Workspace. You will see a popup box appear, asking you to configure your Workspace Give your Workspace clone a name by adding an underscore (“_“) and your name. For example, \"demos-combine-data-workspaces_Firstname_Lastname\". Select the Billing Project provided by your instructor. Leave the bottom two boxes as-is. Click “CLONE WORKSPACE”. The new Workspace should now show up under “MY WORKSPACES”. You now have your own copy of the Workspace to work in. Now your Workspace should be ready for you by the time you need it below. You are ready to begin! 10.4 Start Cloud Environment You will need to launch the interactive RStudio environment to proceed. 10.4.1 Video Overview Here is a video tutorial that describes the basics of using RStudio on AnVIL. 10.4.2 Objectives Start compute for your RStudio environment Tour RStudio on AnVIL Stop compute to minimize expenses 10.4.3 Slides The slides for this tutorial are are located here. 10.4.4 Launching RStudio AnVIL is very versatile and can scale up to use very powerful cloud computers. It’s very important that you select a cloud computing environment appropriate to your needs to avoid runaway costs. If you are uncertain, start with the default settings; it is fairly easy to increase your compute resources later, if needed, but harder to scale down. Note that, in order to use RStudio, you must have access to a Terra Workspace with permission to compute (i.e. you must be a “Writer” or “Owner” of the Workspace). Open Terra - use a web browser to go to anvil.terra.bio In the drop-down menu on the left, navigate to “Workspaces”. Click the triple bar in the top left corner to access the menu. Click “Workspaces”. Click on the name of your Workspace. You should be routed to a link that looks like: https://anvil.terra.bio/#workspaces/&lt;billing-project&gt;/&lt;workspace-name&gt;. Click on the cloud icon on the far right to access your Cloud Environment options. If you don’t see this icon, you may need to scroll to the right. In the dialogue box, click the “Settings” button under RStudio. You will see some configuration options for the RStudio cloud environment, and a list of costs because it costs a small amount of money to use cloud computing. Configure any settings you need for your cloud environment. If you are uncertain about what you need, the default configuration is a reasonable, cost-conservative choice. It is fairly easy to increase your compute resources later, if needed, but harder to scale down. Scroll down and click the “CREATE” button when you are satisfied with your setup. The dialogue box will close and you will be returned to your Workspace. You can see the status of your cloud environment by hovering over the RStudio icon. It will take a few minutes for Terra to request computers and install software. When your environment is ready, its status will change to “Running”. Click on the RStudio logo to open a new dialogue box that will let you launch RStudio. Click the launch icon to open RStudio. This is also where you can pause, modify, or delete your environment when needed. You should now see the RStudio interface with information about the version printed to the console. "],["single-cell-with-bioconductor-exercises.html", "11 Exercises 11.1 Loading the Data 11.2 Installing iSEE 11.3 Panel Display 11.4 Visualize Cell Type Assignment 11.5 Visualize Expression of a Single Gene 11.6 Get Session Info 11.7 Shutting Down", " 11 Exercises The following exercises will walk you through the process of using iSEE to explore single cell RNA-seq data. You will use data that have already been prepared and is saved in a SingleCellExperiment object. You will use the pbmc3k dataset from the TENxPBMCData package, which contains gene expression profiles for 2,700 single peripheral blood mononuclear cells. Information on how the data were preprocessed can be found here. These exercises were adapted from iSEEWorkshopEuroBioc2020/. To follow along with these exercises, you will need to complete the steps described in the Preparation guide for this demo. 11.1 Loading the Data First, we’ll want to load the data that we’ll be using. To do that, we’ll need to load the AnVIL package created by the Bioconductor team for interfacing with files on AnVIL. Luckily, it’s already installed. library(AnVIL) Next, we’ll use the avfiles_restore() function from the AnVIL package to actually bring the data into our environment’s persistent disk. avfiles_restore( source = &quot;sc_bioconductor_data.RData&quot;, namespace = &quot;anvil-outreach&quot;, name = &quot;demos-single-cell-bioconductor&quot; ) In the code above, we are copying the file sc_bioconductor_data.RData from the Workspace demos-single-cell-bioconductor. It was created under the anvil-outreach Billing Project. 11.2 Installing iSEE Once you’ve loaded the data, you’ll want to install and load the iSEE library. You can easily install it into your own personal RStudio environment using the pre-installed BiocManager commands. BiocManager::install(&#39;iSEE&#39;) library(iSEE) 11.3 Panel Display First we will take a look at the interactive plots that iSEE can display. 11.4 Visualize Cell Type Assignment Next, let’s focus specifically on visualizing cell type assignment by cluster membership. The goal is to identify the predominant cell type in each cluster. We can do this by plotting the column data in a ColumnDataPlot. First, select the panel organization button and select “Organize panels”. Remove all plots except for the column data plot. This will make things easier to view. Change the width to 12. You should now see a large scatter plot. Select “Data parameters” underneath the plot. First, select “labels_fine” under “Column of interest (Y-axis)”. Directly below, select the “Column data” button for “X-axis”. Once the dropdown menu appears for “Column of interest (X-axis)”, select “Cluster”. Since both cell annotations and the cluster are categorical, iSEE will generate a visual representation of a matrix called a “Hinton plot”. Now we know that cluster 4 contains almost all the cells that were annotated as classical monocytes. On the other hand, T cells can be found in multiple clusters. We can also save the R code used to create our iSEE plots. This helps make our work reproducible! 11.5 Visualize Expression of a Single Gene Now let’s take a look at the expression data of a single gene across all the clusters. We can use the “Feature assay plot” panel to plot the distribution of the logcount values for a particular gene. Click on the “Organize Panels” icon in the top right corner. Remove the “column plot” and choose “feature assay plot”. Change the width of the plot to 12. You should now see a rather underwhelming bar plot. We still need to change the data parameters, so click on the “Data parameters” box. Next, change the “Y-axis feature” to “LYZ”. This is the gene whose expression we’ll be examining. Change the feature selection box to “logcounts.” The LYZ gene encodes an enzyme called lysozyme, which plays a crucial role in the immune system’s defense against bacterial infections. The primary function of lysozyme is to break down bacterial cell walls. The highest levels of LYZ gene expression are typically observed in tissues with direct contact with the external environment, such as the epithelial cells of the respiratory tract, gastrointestinal tract, and genitourinary system. These tissues are often exposed to potential pathogens, and the expression of lysozyme helps provide an additional line of defense against bacterial invasion. Next, click the “column data” button under the “X-axis” header. Finally, choose “Cluster” from the drop down menu of “X-axis column data.” Now we have a much more exciting violin plot of LYZ gene expression levels across the 14 clusters in our dataset. LYZ is expressed more in clusters 4, 8, 9, and 13. We might be interested in also displaying cell type information in this plot, which we can do using the Visual Parameters options. Click the “Visual parameters” box. Make sure “Color” is checked in the first row. Choose “Column Data” under the “Color by” options and change the drop down menu to “labels_main”. We could also choose to color the data by “labels_fine”. We should see the dots in our violin plot colored by cell type annotation. Three of the clusters which have higher LYZ expression contain large numbers of cells identified as monocytes. Since LYZ codes for a human lysosome protein and is often used as a marker gene for monocytes, this makes a lot of sense. Monocytes are a subset of white blood cells that play a pivotal role in our immune defense against infections. Upon encountering an infection or inflammation, they migrate from the bloodstream to the affected tissues, where they differentiate into specialized cells that engulf and eliminate pathogens. Let’s download this plot. Click on the “download” button in the top right corner like we did before, but this time choose “Download panel output”. A box will pop up asking you to choose which plots to download. This means you could have multiple plots being displayed in your panel but only choose to download a subset of them. Make sure “Feature assay plot” is checked and click “Download”. Your figure will be saved in a zip file in your Downloads folder. Your turn! CD14 is a marker gene for the same type of cells as LYZ. Does it have the same cluster expression pattern as what we saw for LYZ? 11.6 Get Session Info It’s a good idea to document information about the packages (and their versions) you used while running the analysis. The last codeblock uses the sessionInfo() command to do just that. Here’s an example of what that might look like: sessionInfo() ## R version 4.3.2 (2023-10-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 22.04.4 LTS ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so; LAPACK version 3.10.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## time zone: Etc/UTC ## tzcode source: system (glibc) ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] sass_0.4.8 utf8_1.2.4 generics_0.1.3 xml2_1.3.6 ## [5] stringi_1.8.3 lattice_0.21-9 hms_1.1.3 digest_0.6.34 ## [9] magrittr_2.0.3 evaluate_0.23 grid_4.3.2 timechange_0.3.0 ## [13] bookdown_0.41 fastmap_1.1.1 rprojroot_2.0.4 jsonlite_1.8.8 ## [17] Matrix_1.6-1.1 processx_3.8.3 chromote_0.3.1 ps_1.7.6 ## [21] promises_1.2.1 httr_1.4.7 fansi_1.0.6 ottrpal_1.3.0 ## [25] udpipe_0.8.11 cow_0.0.0.9000 jquerylib_0.1.4 cli_3.6.2 ## [29] rlang_1.1.4 gitcreds_0.1.2 cachem_1.0.8 yaml_2.3.8 ## [33] tools_4.3.2 tzdb_0.4.0 dplyr_1.1.4 curl_5.2.0 ## [37] vctrs_0.6.5 R6_2.5.1 lifecycle_1.0.4 lubridate_1.9.3 ## [41] snakecase_0.11.1 stringr_1.5.1 janitor_2.2.0 pkgconfig_2.0.3 ## [45] later_1.3.2 pillar_1.9.0 bslib_0.6.1 data.table_1.15.0 ## [49] glue_1.7.0 Rcpp_1.0.12 highr_0.11 xfun_0.48 ## [53] tibble_3.2.1 tidyselect_1.2.0 knitr_1.48 textrank_0.3.1 ## [57] websocket_1.4.2 htmltools_0.5.7 igraph_2.0.2 rmarkdown_2.25 ## [61] webshot2_0.1.1 readr_2.1.5 compiler_4.3.2 askpass_1.2.0 ## [65] openssl_2.1.1 11.7 Shutting Down Pausing your cloud environment only temporarily stops your work. When you are ready to delete the cloud environment, click on the RStudio icon on the right-hand side and select “Settings”. If you don’t see this icon, you may need to scroll to the right. Click on “Delete Environment”. If you are certain that you do not need the data and configuration on your disk, you should select “Delete everything, including persistent disk”. If there is anything you would like to save, open the compute environment and copy the file(s) from your compute environment to another location, such as the Workspace bucket, GitHub, or your local machine, depending on your needs. Select “DELETE”. You can also delete your cloud environment(s) and disk storage at https://anvil.terra.bio/#clusters. "],["instructor-guide.html", "12 Instructor Guide", " 12 Instructor Guide Coming soon! "],["create-workflows-with-galaxy-overview.html", "13 Overview 13.1 Learning Objectives", " 13 Overview 13.1 Learning Objectives Learn how to launch Galaxy in AnVIL and import data Understand how to find, import, and run workflows Visualize a sample variant using JBrowse Learn how to save your history back to AnVIL Show how to shut down Galaxy in AnVIL "],["create-workflows-with-galaxy-preparation.html", "14 Preparation 14.1 Review Key Concepts 14.2 Clone Workspace 14.3 Start Cloud Environment", " 14 Preparation 14.1 Review Key Concepts This 5-min video provides a high level summary of the exercises to follow. Several important concepts are introduced to provide context for the exercises (slides). 14.2 Clone Workspace For this demo, you will need your own copy of the SARS-CoV-2-Genome Workspace. These instructions will walk you through cloning a copy of the Workspace. 14.3 Start Cloud Environment Note that, in order to use Galaxy, you must have access to a Terra Workspace with permission to compute (i.e. you must be a “Writer” or “Owner” of the Workspace). Open your Workspace, and click on the “Environment configuration” button, a cloud icon on the righthand side of the screen. Under Galaxy, click on “Create new Environment”. Click on “Next” and “Create” to keep all settings as-is. This will take 8-10 minutes. Click on “Open Galaxy” when the environment is ready. "],["create-workflows-with-galaxy-exercises.html", "15 Exercises 15.1 Import Data 15.2 Find Workflow 15.3 Run Workflow 15.4 Explore Results 15.5 Export History 15.6 Shut Down", " 15 Exercises 15.1 Import Data 15.2 Find Workflow 15.3 Run Workflow 15.4 Explore Results 15.5 Export History 15.6 Shut Down "],["create-workflows-with-galaxy-instructor-guide.html", "16 Instructor Guide 16.1 Timeline", " 16 Instructor Guide 16.1 Timeline "],["run-tool-with-galaxy-overview.html", "17 Overview 17.1 Learning Objectives", " 17 Overview This chapter contains instructions for the SARS-CoV-2 sequencing data FastQC analysis with Galaxy on AnVIL activity. Galaxy is a free computing platform that allows users to upload or “fetch” data from online repositories and analyze that data with supported tools using a point and click user interface (UI) rather than with a command-line interface. Galaxy on AnVIL means that the benefits of AnVIL (such as secure data sharing, access to controlled access data) are combined with the benefits of running a reproducible analysis with Galaxy. Like all compute on AnVIL, Galaxy on AnVIL will incur costs. 17.1 Learning Objectives This activity will teach you how to use the AnVIL platform to: Launch Galaxy on AnVIL Import data into Galaxy on AnVIL Examine sequence data files (.fastq files) Find, open, and run a tool (FastQC) Examine the quality control summary report (Webpage) Export your results for future viewing Show how to shut down Galaxy on AnVIL "],["run-tool-with-galaxy-getting-started.html", "18 Getting Started 18.1 Account Login 18.2 Workspace Set Up", " 18 Getting Started 18.1 Account Login If you don’t have an AnVIL account, you will need to create one using the steps below in the AnVIL Account Creation Dropdown section. Expand for AnVIL account creation instructions In order to run your analyses, you will use the AnVIL cloud computing platform. The AnVIL (Analysis Visualization and Informatics Lab-space) platform is specially designed for analyzing biological data, and is used by scientists doing all sorts of biological research. AnVIL in a nutshell Behind the scenes, AnVIL relies on Google Cloud Platform to provide computing infrastructure. Basically, AnVIL lets you “rent” computers through the internet. The analysis is run on the rented computer. AnVIL lets you see the results in your browser. AnVIL uses Terra to provide many computational tools useful for biological data analysis, such as RStudio, Galaxy, and Jupyter Notebooks. Terra takes care of installing these tools so you can use them right away. 18.1.1 Create Google Account First, you will need to set up a (free) Google account. A Google account usually looks like “myname@gmail.com”. Alternatively, you can enable Google for an existing non-Gmail email address using these instructions. If you do not already have a Google account that you would like to use for accessing AnVIL, create one now. 18.1.2 Log In to Terra Next, make sure you can log in to Terra – you will use Terra to perform computations on AnVIL. You can access Terra by going to anvil.terra.bio. Open Terra, and you should be prompted to sign in with your Google account. 18.1.3 Share Username Make sure your instructor has your Google account username (e.g. myname@gmail.com), so they can give you access to everything you need. Make sure there are no typos! If you have multiple Google accounts, make sure you give them the username that you will be using to log in to anvil.terra.bio. It is very important that you share the Google account you will be using to access AnVIL with with your instructor! Otherwise, the instructor cannot add you to Billing Projects or Workspaces, and you will be unable to proceed with your assignments. Once you have an account, you can login and access Terra by going to anvil.terra.bio. Open Terra, and you should be prompted to sign in with your Google account. 18.2 Workspace Set Up Workspaces are the building blocks of projects in Terra. Inside a Workspace, you can run analyses, launch interactive tools like RStudio and Galaxy, store data, and share results. Cloning an existing Workspace allows you to copy existing documentation, code, and/or data into your own experimental space. The data for this activity is already available on AnVIL, specifically the demos-galaxy-fastqc workspace, so you’ll want to clone the repository. When cloning, AnVIL makes a copy of notebooks and code for you to modify. Data however, is linked back to the original Workspace through Data Tables, which saves space! The screenshots included below show a different workspace than what this tutorial will be using. For this tutorial, you want to clone the demos-galaxy-fastqc workspace Be sure to name the cloned workspace a unique name in step 6. We recommend adding _yourfirstname_yourlastname to the workspace name. This will not work until your instructor has given you permission to spend money to “rent” the computers that will power your analyses (by adding you to a “Billing Project”). On AnVIL, you access files and computers through Workspaces. Each Workspace functions almost like a mini code laboratory - it is a place where data can be examined, stored, and analyzed. The first thing we want to do is to copy or “clone” a Workspace to create a space for you to experiment. This will give you access to the files you will need (data, code) the computing environment you will use Tip At this point, it might make things easier to open up a new window in your browser and split your screen. That way, you can follow along with this guide on one side and execute the steps on the other. To clone an AnVIL Workspace: Open Terra - use a web browser to go to anvil.terra.bio In the drop-down menu on the left, navigate to “Workspaces”. Click the triple bar in the top left corner to access the menu. Click “Workspaces”. You are automatically directed to the “MY WORKSPACES” tab. Here you can see any Workspaces that have been shared with you, along with your permission level. Depending on how your instructor has set things up, you may or may not see any Workspaces in this tab. Locate the Workspace demos-galaxy-fastqc. (The images below show the SARS-CoV-2-Genome Workspace as an example, but you should look for the Workspace demos-galaxy-fastqc.) If it has been shared with you ahead of time, it will appear in “MY WORKSPACES”. Otherwise, select the “PUBLIC” tab. In the top search bar, type the Workspace name demos-galaxy-fastqc. You can also go directly to the Workspace by clicking this link: https://anvil.terra.bio/#workspaces/anvil-outreach/demos-galaxy-fastqc. Clone the workspace by clicking the teardrop button (). Select “Clone”. Or, if you have opened the Workspace, you can find the teardrop button on the top right of the Workspace. You will see a popup box appear, asking you to configure your Workspace Give your Workspace clone a name by adding an underscore (“_“) and your name. For example, \"demos-galaxy-fastqc_Firstname_Lastname\". Select the Billing Project sri-lanka-2025. Leave the bottom two boxes as-is. Click “CLONE WORKSPACE”. The new Workspace should now show up under “MY WORKSPACES”. You now have your own copy of the Workspace to work in. "],["run-tool-with-galaxy-activity.html", "19 Activity 19.1 Launching Galaxy on AnVIL 19.2 Importing Data into Galaxy on AnVIL 19.3 Examining fastq sequence data files 19.4 Finding and Using FastQC 19.5 Examining the FastQC quality control summary report 19.6 Exporting your results 19.7 Shutting down Galaxy on AnVIL", " 19 Activity 19.1 Launching Galaxy on AnVIL Note that, in order to use Galaxy, you must have access to a Terra Workspace with permission to compute (i.e. you must be a “Writer” or “Owner” of the Workspace). Open your Workspace, and click on the “Environment configuration” button, a cloud icon on the righthand side of the screen. Under Galaxy, click on “Create new Environment”. Click on “Next” and “Create” to keep all settings as-is. This will take 8-10 minutes. Click on “Open Galaxy” when the environment is ready. 19.1.1 Navigating Galaxy on AnVIL Notice the three main sections. Tools - These are all of the bioinformatics tool packages available for you to use. The Main Dashboard - This contains flash messages and posts when you first open Galaxy, but when we are using data this is the main interface area. History - When you start a project you will be able to see all of the documents in the project in the history. Now be aware, this can become very busy. Also the naming that Galaxy uses is not very intuitive, so you must make sure that you label your files with something that makes sense to you. On the welcome page, there are links to tutorials. You may try these out on your own. If you want to try a new analysis this is a good place to start. 19.2 Importing Data into Galaxy on AnVIL When we cloned our workspace, our cloned workspace linked to the original data! We will upload three files from the AnVIL workspace into Galaxy, though we need only one fastq data sequence file for our activity. The others will be used if you want to continue with a related activity that performs alignment and variant discovery after quality control. These three files are (1) the forward and (2) the reverse reads for our sample, as well as, (3) the reference genome for SARS-CoV-2. There are two sets of reads for our sample because the scientists who collected it used paired-end sequencing. The sample files we are looking at end in fastq because they are raw data from the sequencer. The reference genome ends in .fasta because it has already been cleaned up by scientists. Click on “Upload Data” in the Tools pane. Click on “Choose remote files” at the bottom of the popup. If you had files locally on your computer that you wanted to upload, you would use the “Choose local file” button. Or if you had files you wanted to import from a data repository like Zenodo, you would use the “Paste/Fetch data” button. We’re using the “Choose remote files” button because we have data in our AnVIL workspace that we can import into the Galaxy on AnVIL instance. Double-click the Workspace folder. Upload the sample sequence data files Double-click “Tables/” Then double-click “sample/”. Click the two sample .fastq file checkboxes to select them. These files will be highlighted in green when ready. Click “Ok”. Expand for Steps 5- 6: Upload the reference genome Repeat steps 2 and 3 from above. Click on “Choose remote files” at the bottom of the popup. Double-click the Workspace folder. Upload the reference genome file Again, double click “Tables/”. This time, double click “reference/”. Click the fasta file. This file will be highlighted green and click “Ok”. 7. Click “Start” Once complete, click “Close”. Confirm that the files uploaded successfully by looking at the file names in the Galaxy History pane. Note that the files will be highlighted in green in the Galaxy History pane once they are uploaded and available. 19.3 Examining fastq sequence data files We will examine data in fastq format. This is the typical output from an Illumina Sequencer, but also the standard format output from most sequencers. Use your mouse and click on the eye icon () of the first fastq file (VA_sample_forward_reads.fastq). After clicking the eye icon, in the Main screen you will see something like this: Expand for FASTQ files explained For more information on the contents of a FASTQ file, consider this resource from Illumina. QUESTIONS: How many lines in a .fastq file represent an individual read? What does each line represent? Why is the final line for each read (the quality score) important? Breakout Box: Learn more about quality scores To save space, the sequencer records an ASCII character to represent scores 0-42. For example 10 corresponds to “+” and 40 corresponds to “I”. FastQC (a tool we’ll be using next) knows how to translate this. This way of encoding the data is often called “Phred” scoring. What does 0-42 represent? These numbers, when plugged into a formula, tell us the probability of an error for that base. This is the formula, where Q is our quality score (0-42) and P is the probability of an error: Q = -10 log10(P) Using this formula, we can calculate that a quality score of 40 means only 0.00010 probability of an error! 19.4 Finding and Using FastQC FastQC is a tool which aims to provide simple quality control checks on raw sequence data coming from high throughput sequencing pipelines. It provides a set of analyses which you can use to get a quick impression of whether your data has any problems of which you should be aware before doing any further analysis. Use the search tools bar in the upper left (within the tools pane in Galaxy) Type fast to search for FastQC, and select the tool in the list below. This will open the tool menu in the middle pane. Switch the version of FastQC to 0.73+galaxy0 Select the Versions icon (3 cubes). Select “Switch to 0.73+galaxy0” from the dropdown menu. Confirm that the version now says “Selected 0.73+galaxy0”. Confirm or select the correct input for FastQC (the forward reads fastq file). Run FastQC by clicking the blue “Run Tool” button. After submitting the job to run, the middle pane should have a message highlighted in green. The history pane should also list what will be the output(s) from the tool. Note, before the job has finished running, these output(s) will be highlighted in gray. While running, the output(s) will be highlighted in an orange cream color. And once the tool runs successfully, the output(s) will be highlighted in green. 19.5 Examining the FastQC quality control summary report We will examine the FastQC output in webpage or html format. This form of the output provides graphs and a flag of “Passed”, “Warn”, or “Fail” for each subsection within the quality control analysis. Use your mouse and click on the eye icon () of the FastQC Webpage output (FastQC on data 1: Webpage). This will open up a summary report for the sequencing file in the middle pane that you can scroll. Expand for FastQC summary report explained For more information on the contents of the output quality control summary report from FastQC, consider this resource from Michigan State QUESTIONS: Explore “Basic Statistics”. How many total reads are there? Have any been flagged as poor quality? What is the sequence length? Explore “Per base sequence quality”. Based on the Basic Statistics, is 28-40 a good or bad quality score? Is it okay to proceed based on the per base sequence quality? 19.6 Exporting your results In case you want to view the results later, you can download the file. Click on the name of the results you want to export/save, and it will expand the info shown for that file. Click the floppy disk/save icon. This will download a zip (compressed) file with the results to your computer. Uncompress it to view it locally. 19.7 Shutting down Galaxy on AnVIL Once you are done with your activity, you’ll need to shut down your Galaxy cloud environment. This frees up the cloud resources for others and minimizes computing cost. The following steps will delete your work, so make sure you are completely finished at this point. Otherwise, you will have to repeat your work from the previous steps. Return to AnVIL, and find the Galaxy logo that shows your cloud environment is running. Click on this logo. Next, click on “Settings”. Click on “Delete Environment”. Finally, select “Delete everything, including persistent disk”. Make sure you are done with the activity and then click “Delete”. "],["run-tool-with-galaxy-next-steps.html", "20 Next steps", " 20 Next steps This tutorial is just a first step in working with this data, specifically considering the quality scores of one set of the sequencing reads. Next steps include running FastQC on the reverse reads and downstream applications such as alignment and variant detection. Walk-throughs for these next steps can be found in this Genomic Data Science Community Network Lab Exercise Book or this AnVIL Demos Recording. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
