```{r echo = FALSE}
knitr::opts_chunk$set(out.width = "100%")
```

# (PART\*) Scale with Workflows {-}   

# Overview

One of the great features of AnVIL is that it "brings the analysis to the data". Rather than downloading and storing your own copy of an AnVIL dataset, you can simply create links to the existing data, and run analyses using those links.

Here is a video overview of this demo.

<br>

<iframe src="https://drive.google.com/uc?id=1vq9l8jvTd8mIEUWdpzmSOQI7kn9vo_4g" width="640" height="360" allow="autoplay"></iframe>

## Skills Level

::: {.notice}
_Genetics_

**Novice**: no genetics knowledge needed

_Programming skills_

**Novice**: no programming experience needed
:::

## Learning Objectives

1. Identify interesting datasets in the AnVIL Dataset Catalog
1. Navigate an AnVIL Workspace
1. Combine data from multiple existing datasets into your own Workspace
1. Find Workflows in Dockstore
1. Run a Workflow on AnVIL with your combined data


# Preparation {#scale-with-workflows-preparation}

If you plan to follow along with these exercises, there are a couple of things you will need to take care of first:

## Create AnVIL account

You will need an AnVIL account in order to view Workspaces and run analyses.

- If you do not already have an account, follow [these instructions](https://jhudatascience.org/AnVIL_Book_Getting_Started/overview-analysts.html) to set one up.  (You do not need to link any external accounts for these exercises.)
- Make sure that your Instructor (if participating in a workshop) or PI / Lab Manager has your username, so that they can add you to an appropriate *Billing Project*.  You can't clone or create Workspaces on AnVIL without a Billing Project.

## Clone Workspace

When you "clone" a copy of an AnVIL Workspace, it can take a few minutes for everything to propogate to your new Workspace. If you are participating in a course or workshop, your instructor may have you start by cloning the Workspace, so that it is ready by the time you need it. (If you are working at your own pace, feel free to come back to this step later, when you're ready to start using the Workspace.)

Follow the instructions below to clone your own copy of the Workspace for this Demo.

:::: {.borrowed_chunk}
```{r, echo = FALSE, results='asis'}
# Specify variables
AnVIL_module_settings <- list(
  workspace_name = "shorts-combine-data-workspaces",
  workspace_link = "https://anvil.terra.bio/#workspaces/anvil-outreach/shorts-combine-data-workspaces"
)

cow::borrow_chapter(
  doc_path = "child/_child_student_workspace_clone.Rmd",
  repo_name = "jhudsl/AnVIL_Template"
)
```
::::

Now your Workspace should be ready for you by the time you need it below.  You are ready to begin!

# Exercises

The following exercises will walk you through the process of finding datasets that are stored in AnVIL Workspaces and bringing that data into your own Workspace so that you can analyze it.

:::{.notice}
To follow along with these exercises, you will need to complete the steps described in the [Preparation](#scale-with-workflows-preparation) guide for this demo.
:::

## Explore Dataset Catalog

First we will take a look at the [AnVIL Dataset Catalog]((https://anvilproject.org/data/)).  Here you can browse the datasets available on AnVIL.

```{r, echo=FALSE, fig.alt='Screenshot of AnVIL Dataset Catalog'}
ottrpal::include_slide("https://docs.google.com/presentation/d/1K2qqm02W_zPhrOZsUoKj1FvKWcMO0iHgaiVwvcqMrXc/edit#slide=id.g24306c8bf8a_0_0")
```


:::{.reflection}

### Exercise {-}

Use a web browser to navigate to [`anvilproject.org/data/`](https://anvilproject.org/data/) and answer the following questions.

**Q1.**  Which Consortium has the most participants?
    
- You can click on a column name to sort by that column.
- Click again to switch between ascending and descending.
    
**Q2.**  Where would you find data from the Genotype-Tissue Expression (GTEx) Project?
    
- You can use the filters on the left to find specific datasets.  Click on either the Consortium or the Study filter to search for GTEx data.
    
**Q3.**  How many Workspaces have consent code NRES (No REStrictions on data use)?
    
- You can use the filters on the left to browse and narrow down on datasets that fit your needs.  Click on the Consent Code filter to select for datasets that you can access.

:::
    
Now you know how to find AnVIL datasets!  To access the data in these datasets, you will need to access the **Terra Workspace** where the data is stored.  You can find links to the Terra Workspaces in the Workspaces tab.

```{r, echo=FALSE, fig.alt='Screenshot of AnVIL Dataset Catalog showing Workspaces from the GTEx project.  The "Workspaces" tab is highlighted and has been selected, and the "Terra Workspaces" column is highlighted.'}
ottrpal::include_slide("https://docs.google.com/presentation/d/1K2qqm02W_zPhrOZsUoKj1FvKWcMO0iHgaiVwvcqMrXc/edit#slide=id.g24f1d151022_0_4")
```

Note that, if a Workspace contains protected data, you will need to obtain the appropriate permissions before you can open the Workspace.  For these GTEx datasets, `AnVIL_GTEx_public_data` (with consent code NRES) is available to anyone on AnVIL, but other GTEx Workspaces require permission to access.


## Explore 1000G Workspace

Next we will explore one of the Workspaces from the AnVIL Dataset Catalog, so you can see where the data lives.  For this exercise, we will look at data from the [1000 Genomes Project](https://www.internationalgenome.org/).

You can find the Workspace that contains the data by searching for the "1000G" Consortium in the AnVIL Dataset Catalog and clicking on the Terra Workspace link, or you can navigate there directly through this link: https://anvil.terra.bio/#workspaces/anvil-datastorage/1000G-high-coverage-2019.

```{r, echo=FALSE, fig.alt='Screenshot of AnVIL Dataset Catalog showing the 1000 Genomes Workspace.  The "Consortium" filter is highlighted and "1000G" has been selected; the "Workspaces" tab is highlighted and has been selected, and in the Terra Workspaces column the link to the "1000G-high-coverage-2019" Workspace is highlighted.'}
ottrpal::include_slide("https://docs.google.com/presentation/d/1K2qqm02W_zPhrOZsUoKj1FvKWcMO0iHgaiVwvcqMrXc/edit#slide=id.g24f280a88cb_0_12")
```

### What is a Workspace?

Workspaces are the building blocks of projects in Terra. Inside a Workspace, you can run analyses, launch interactive tools like RStudio and Galaxy, store data, and share results.  The `1000G-high-coverage-2019` Workspace is being used to store and share data from the 1000 Genomes Project.

Note that, since you are only a "Reader", you will be unable to do any computations directly in this Workspace.  To run analyses, you will need a Workspace of your own.

Workspaces can serve different purposes.  For example, it's often useful to use one Workspace just for organizing primary data, and then to carry out analyses in a separate Workspace.  Storing data in a standalone Workspace helps keep it clean and organized, since it won't get cluttered up with results and intermediate files from your analyses.  It also ensures you can easily see and manage who has access to the data, and allows multiple AnVIL users to use the data without getting in each others' way.


### Dashboard

When you first open a Workspace, you will be directed to the **Dashboard** tab.  The Dashboard is like a README for the Workspace - it should contain information to help you understand the purpose and organization of the Workspace.  On the right, you can see some basic information about the Workspace such as the usernames of the Owners as well as your permission level for the Workspace.  The left side typically contains a description of the Workspace's contents and purpose.

```{r, echo=FALSE, fig.alt='Screenshot of the Dashboard for the 1000 Genomes Workspace.'}
ottrpal::include_slide("https://docs.google.com/presentation/d/1K2qqm02W_zPhrOZsUoKj1FvKWcMO0iHgaiVwvcqMrXc/edit#slide=id.g24f280a88cb_0_20")
```

:::{.reflection}
### Exercise {-}

**Q1.** What versions of BWA-MEM and GATK were used to process the 1000 Genomes data?

- Look through the Workspace's description to see what information has been provided about the data in this Workspace.

:::

### Data

The **Data** tab contains all the files associated with the Workspace - data, metadata, workflow outputs, etc.  Terra provides **Data Tables** to help organize data and results.

```{r, echo=FALSE, fig.alt='Screenshot of the Data tab for the 1000 Genomes Workspace.  The "TABLES" menu is expanded and highlighted.'}
ottrpal::include_slide("https://docs.google.com/presentation/d/1K2qqm02W_zPhrOZsUoKj1FvKWcMO0iHgaiVwvcqMrXc/edit#slide=id.g24f280a88cb_0_25")
```

:::{.reflection}
### Exercise {-}

Take a minute to look through the Data Tables for the `1000G-high-coverage-2019` Workspace.

**Q2.** What types of files are linked to in the Data Table named `sample`?

**Q3.** What quality control statistics are available in the Data Table named `qc_results_sample`?

:::

A key feature of Terra is that **Data Tables can link to files in other Workspaces** or even files that live outside of Terra.  This means that you don't need to maintain your own copy of AnVIL datasets; you can simply link to the data from a Data Table within your own Workspace to use it in your workflows.


## Combine Data Workspace

Next we will go over how to set up a Data Table so that you can use data from another Workspace in your own analysis.

:::{.notice}
For this exercise, you will need your own copy of the [`shorts-combine-data-workspaces`](https://anvil.terra.bio/#workspaces/anvil-outreach/shorts-combine-data-workspaces) Workspace.  If you have not already done so, follow the instructions in the [Preparation](#scale-with-workflows-preparation) section to clone a copy of the Workspace now.
:::


### Open your Workspace

To get started, navigate to your cloned copy of `shorts-combine-data-workspaces`.  You can find your Workspace in Terra by clicking on "Workspaces" in the dropdown menu, or you can go there directly at [`anvil.terra.bio/#workspaces`](https://anvil.terra.bio/#workspaces).

Once there, you should see your Workspace under the "MY WORKSPACES" tab.  It may also show up in your recently viewed Workspaces.  Click on the Workspace name to open it.  **Make sure you are in *your copy* of the Workspace.**  If you are in the original Workspace, you will not have permission to start up Jupyter and run commands.

```{r, echo=FALSE, fig.alt='Screenshot of Terra Workspaces page with the "My Workspaces" tab selected.  The name of the Workspace is highlighted.'}
ottrpal::include_slide("https://docs.google.com/presentation/d/1K2qqm02W_zPhrOZsUoKj1FvKWcMO0iHgaiVwvcqMrXc/edit#slide=id.g24f280a88cb_0_44")
```

### Open Jupyter Notebook

There are multiple ways to manage Data Tables on AnVIL; for this exercise we will use the [`Anvil`](https://bioconductor.org/packages/release/bioc/html/AnVIL.html) R package, which we will run using a Jupyter cloud environment.  The `AnVIL` package provides a wide range of functions for programatically interacting with AnVIL.

To help you get started, we have provided a copy of a Jupyter Notebook that uses the `AnVIL` package to create Data Tables linking out to data in another Workspace.  For this exercise, you will make a couple of adjustments to the Notebook, so that it links properly to *your* Workspace (instead of the original Workspace).

The ANALYSIS tab holds your Notebooks (Jupyter and RMarkdown).

[SCREENSHOT]

By clicking on a Notebook, you can preview a static copy of the Notebook.  Clicking the "OPEN" button launches the Notebook in a cloud environment so that you can edit and run code.

[SCREENSHOT]

:::{.reflection}
### Exercise {-}

In your Workspace, navigate to the "ANALYSIS" tab.  

Click on `combine-data-workspaces.ipynb` to view the Notebook for this exercise, and click the "Open" button so you can edit and run it.

- The Notebook will launch quickly if you already have a Jupyter environment configured.
- If Jupyter is not already set up, accept the default settings and click "Launch".  It will take a few minutes for Jupyter to start up.
:::

This Notebook has four code cells that you will run, after making some edits.

### Load Packages

The first code cell loads R packages that are needed for this exercise.  You do not need to make any adjustments here.

:::{.reflection}
### Exercise {-}

**1.** Click on the code cell under "Load Packages", then click the Run button to load the packages.

You should see some messages appear below the cell.
:::


### Retrieve original file locations

The next two cells find the links to the original data.  Here we are bringing in data from two different Workspaces, `1000G-AMR` and `1000G-EAS`, which contains 1000 Genomes Project data from the Americas and East Asia, respectively.

- `avworkspace( "anvil-outreach/1000G-AMR" )` tells the AnVIL package what Workspace to access
- `df_sample_amr <- avtable( "sample" ) %>% top_n( -2 )` tells it to look at the table named "sample" and to grab the bottom two samples.

:::{.notice}
It's often a good idea to start off a new analysis by working with just a few samples.  This can help you minimize wasted time and computing expenses while you figure out your pipeline, and can also help you estimate what your costs will be for processing larger dataset before commiting to a large Workflow run.
:::

To keep this exercise short and cheap, we're just importing a few samples into your Workspace, but when working on your own projects you can use the same process to import whole tables.

It does not cost anything to add these samples to your Data Table, since you are not storing them in your own Workspace, only linking to them in another Workspace.  Costs come into it when you start running analyses on the samples (as we will in a later exercise), so take care not to unintentially run an expensive analysis on a large table of samples.

:::{.reflection}
### Exercise {-}

**2.** Modify the code in both cells to get 3 samples instead of 2, and run each cell.

You should see a table listing out the samples appear below each cell.  Confirm that there are 3 samples in each table.
:::

This step chose the samples we want from the original Workspace, but has not yet created links to them in your own Workspace.

### Exported combined Data Table

The next code block accomplishes a few things:

1. `bind_rows( "AMR"=df_sample_amr, "EAS"=df_sample_eas, .id="code" )` combines data from the two different 1000 Genomes Workspaces into a single data table, so that you can conveniently work with all the data at once in your Workflows.  It also adds a column named "code" to keep track of which samples came from the AMR vs. EAS datasets.
1. `select( sample_id, code, cram )` selects only the columns we care about for our analysis.  Here we are keeping the sample ID, the superpopulation code (AMR or EAS) and the cram file.
1. `avtable_import( namespace="anvil-outreach", name="shorts-combine-data-workspaces" )` creates a Data Table in your Workspace that links to the original data, so that you can easily use it in your analyses.  **This is the line that we need to modify** so that the Data Table is created in *your* Workspace.

:::{.reflection}
### Exercise {-}

You will need two pieces of information so that the AnVIL package can locate your Workspace to create the new Data Table:

1. The `namespace` (the Workspace's Billing Project)
1. The Workspace `name`

You can find both of these in the URL for your Workspace.  For example, for this Workspace:

```
https://anvil.terra.bio/#workspaces/anvil-outreach/shorts-combine-data-workspaces_KCox_20230609
```

- The `namespace` is `anvil-outreach`
- The `name` is `shorts-combine-data-workspaces_KCox_20230609`


**3.** Modify the code in your Notebook so that it points to your Workspace, and run the cell.

If this command is successful, you will not see any output in the Notebook, but if you look in the Data tab of your Workspace you should now see the `sample` Data Table has 6 rows in it.  

:::


### Session Info

It's generally a good idea to document information about the packages (and their versions) you used while running the analysis.  The last codeblock uses the `sessionInfo()` command to do just that.

### View your new Data Table

(If it only has 4 rows...)

## Explore Dockstore Workflows

## Run qc-analysis-pipeline

# Instructor Guide

## Timeline
